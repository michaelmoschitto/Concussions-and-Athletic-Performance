{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# utility\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from data_cleaning import clean_raw_data, create_dataset, get_all_results\n",
    "\n",
    "#viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "# parallel\n",
    "import ray\n",
    "try:\n",
    "    ray.init()\n",
    "except:\n",
    "    print(\"ray already started\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold, StratifiedShuffleSplit, LeaveOneOut\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from augmentdatalib_source.knnor.data_augment import KNNOR\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector, ExhaustiveFeatureSelector\n",
    "from feature_selection import FeatureSelector\n",
    "from tuning import Tuner\n",
    "\n",
    "# models\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# analysis\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.max_columns\", None) # show all cols\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# reload modules in py files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question\n",
    "Can we categorize athletes who actually played on field based on their performance metrics: Binary Classification where the target is to predict if played NHL or not (column J) using performance metrics as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploration / Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_raw_data(\"Brdi_db_march.xlsx\")\n",
    "\n",
    "X, y = create_dataset(df, target_col=\"NHL\")\n",
    "print(X.columns)\n",
    "print(\"No missing values in X: \", (X.isna().sum() == 0).all())\n",
    "print(\"No missing values in y: \", (y.isna().sum() == 0).all())\n",
    "display(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_one = y.value_counts()[1]\n",
    "count_zero = y.value_counts()[0]\n",
    "\n",
    "print(1 / count_zero, 1 / count_one)\n",
    "print(1 / (count_one / len(y)), 1 / (count_zero / len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seaborn_conf_matrix(cm):\n",
    "    group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autopct_format(values):\n",
    "        def my_format(pct):\n",
    "            total = sum(values)\n",
    "            val = int(round(pct*total/100.0))\n",
    "            return '{:.1f}%\\n({v:d})'.format(pct, v=val)\n",
    "        return my_format\n",
    "\n",
    "\n",
    "def plot_pie(df, col, title):\n",
    "    concussions = df.groupby(col).height.count()\n",
    "    colors = sns.color_palette('pastel')[0:5]\n",
    "\n",
    "    plt.title(label=title)\n",
    "    plt.pie(concussions, labels = [\"No\", \"Yes\"], colors = colors, autopct=autopct_format(concussions))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_pie(df, \"NHL\", \"Played in the NHL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling\n",
    "\n",
    "* **SMOTE**\n",
    "* **ADASYN**\n",
    "* **RANDOM** Over Sampling\n",
    "* **KNNOR** - K-nearest neighbors oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(X, y, type=\"SMOTE\"):\n",
    "    techniques = {\n",
    "        \"SMOTE\" : SMOTE(random_state=SEED),\n",
    "        \"ADASYN\" : ADASYN(random_state=SEED),\n",
    "        \"RANDOM\" : RandomOverSampler(random_state=SEED),\n",
    "        \"KNNOR\" : KNNOR(),\n",
    "\n",
    "    }\n",
    "\n",
    "    if type == \"weighted\":\n",
    "        count_one = y.value_counts()[1]\n",
    "        count_zero = y.value_counts()[0]\n",
    "        \n",
    "        y = pd.DataFrame(y)\n",
    "        y[y[\"NHL\"] == 1] = 1 / count_one\n",
    "        y[y[\"NHL\"] == 0] = 1 / count_zero\n",
    "\n",
    "        return X, np.array(y)\n",
    "\n",
    "    sampler = techniques[type]\n",
    "\n",
    "\n",
    "    if type == \"KNNOR\":\n",
    "        X_cols = X.columns\n",
    "        y_name = y.name\n",
    "\n",
    "        X, y, _, _ = sampler.fit_resample(X.values, y.values)\n",
    "        # y = y.reshape(-1, 1)\n",
    "\n",
    "        # because of how the library is setup have to convert back to DF/Series\n",
    "        X = pd.DataFrame(X, columns=X_cols)\n",
    "        y = pd.Series(y, name=y_name)\n",
    "    else:\n",
    "        X, y = sampler.fit_resample(X, y,)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# X_smote, y_smote = balance_dataset(X, y, type=\"SMOTE\")\n",
    "# X_adasyn, y_adasyn = balance_dataset(X, y, type=\"ADASYN\")\n",
    "# X_random, y_random = balance_dataset(X, y, type=\"RANDOM\")\n",
    "# X_knnor, y_knnor = balance_dataset(X, y, type=\"KNNOR\")\n",
    "\n",
    "X_weighted, y_weighted = balance_dataset(X, y, type=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pie(pd.concat([X_smote, y_smote], axis=1), \"NHL\", \"Played in the NHL: SMOTE\")\n",
    "plot_pie(pd.concat([X_adasyn, y_adasyn], axis=1), \"NHL\", \"Played in the NHL: ADASYN\")\n",
    "plot_pie(pd.concat([X_random, y_random], axis=1), \"NHL\", \"Played in the NHL: Random\")\n",
    "plot_pie(pd.concat([X_knnor, y_knnor], axis=1), \"NHL\", \"Played in the NHL: KNNOR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection\n",
    "\n",
    "\n",
    "* **Pearson Correlation** - Two features that are highly correlated with each other are redundant\n",
    "* **Extra Trees Classifier** - Randomized decision trees on subsamples of the dataset to determine feature importance\n",
    "* **Forward Feature Selection** - S.O.A, parallelized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_heatmap(X):\n",
    "    cor = pd.DataFrame(X).corr()\n",
    "    plt.figure(figsize=(25,25))\n",
    "    sns.heatmap(cor, cmap=plt.cm.CMRmap_r,annot=True)\n",
    "    plt.show()  \n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "\n",
    "    \"\"\"\n",
    "    Find all pairs of collumns with correllation > .7. Add one of the pairs to a set to be dropped\n",
    "    \"\"\"\n",
    "    col_corr = set()  \n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: \n",
    "                colname = corr_matrix.columns[i]                  \n",
    "                col_corr.add(colname)\n",
    "    return col_corr  \n",
    "\n",
    "\n",
    "\n",
    "plot_correlation_heatmap(X)\n",
    "orthogonal_features = correlation(X, .7)\n",
    "print(\"Features that exhibit pearson correlation of .7 or more:\\n\",)\n",
    "display(orthogonal_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Extra Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "def get_n_important_features(X, y, n_features=10):\n",
    "    model = ExtraTreesClassifier(random_state=SEED)\n",
    "    model.fit(X, y)\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns).nlargest(n_features)\n",
    "    \n",
    "    top_n_columns=feat_importances.keys().to_list()\n",
    "\n",
    "    top_n_features = pd.DataFrame({'importance' : feat_importances}).sort_values(by=\"importance\", ascending=False)\n",
    "    return top_n_features\n",
    "\n",
    "top_n_features = get_n_important_features(X, y, n_features=15)\n",
    "display(top_n_features)\n",
    "\n",
    "print(\"\\nFeatures that are orthogonal and in the top 15 features:\")\n",
    "set(list(top_n_features.index)).intersection(set(list(orthogonal_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Forward Selection\n",
    "\n",
    "*See ./training_output for all results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_validation(X, y, test_size=.2, n_splits=3, type=\"stratified\"):\n",
    "    if type == \"stratified\":\n",
    "        return list(StratifiedShuffleSplit(test_size=test_size, n_splits=n_splits, random_state=SEED).split(X, y))\n",
    "    elif type == \"leave_one_out\":\n",
    "        return list(LeaveOneOut().split(X, y))\n",
    "\n",
    "kf = get_cross_validation(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Forward Feature Selection\n",
    "\n",
    "* Forward Feature selection, 10-20 features, floating, f1 scoring\n",
    "* 90% training, 10% validation, stratified \n",
    "* Cross Validation: 80% training, 20% testing, stratified, 2 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive that get_cross_val_score is correct\n",
    "\n",
    "Things to note:\n",
    "k = 5 CV\n",
    "\n",
    "test size = .1\n",
    "\n",
    "fit and transforms on training data, applies same transformation to test\n",
    "\n",
    "balances on scaled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_val_score(model, X, y, display_cm=False):\n",
    "    # X = X[features]\n",
    "    kf = get_cross_validation(X, y, n_splits=5, test_size=.1)\n",
    "    scores = []\n",
    "    \n",
    "    all_ytest = []\n",
    "    all_ypred = []\n",
    "\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    \n",
    "    if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "        y = y.values\n",
    "\n",
    "    \n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        display(y_train)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        X_train_scaled, y_train = balance_dataset(X_train_scaled, y_train, type=\"SMOTE\")\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        print(score)\n",
    "        scores.append(score)\n",
    "\n",
    "        all_ytest.extend(y_test)\n",
    "        all_ypred.extend(y_pred)\n",
    "\n",
    "\n",
    "    if display_cm:\n",
    "        seaborn_conf_matrix(confusion_matrix(all_ytest, all_ypred))\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVC\n",
    "\n",
    "Steps: \n",
    "1) Split into train/val 80/20 stratified split \n",
    "2) Scale X_train \n",
    "3) Balance X_train, y_train\n",
    "4) Feature Selection using cross-validation and all features\n",
    "5) Keep only best features in X_val\n",
    "6) Scale X_val (seperately from X_train)\n",
    "7) Retrain model on X_val using CV and best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "model = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# print(get_cross_validation(X_train, y_train, n_splits=2))\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "get_cross_val_score(model, X, y, display_cm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have to worry about data leakage, data used in feature selection can't make it into validation data later on \n",
    "Make sure that X_train in feature selection and X_train in model tuning is the **EXACT** same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "# X_train_not_scaled = X_train.copy().values\n",
    "# X_val_not_scaled = X_val.copy().values\n",
    "# model = SVC(random_state=SEED)\n",
    "model = SVC(random_state=SEED, kernel=\"linear\")\n",
    "kwargs = {\"selection_type\":\"forward\", \"floating\":True, \"scoring\":\"f1\", \"k_features\": len(X.columns), \"cv\": get_cross_validation(X_train, y_train)}\n",
    "cols = X.columns\n",
    "\n",
    "# scale training data\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "# balance data after scaling\n",
    "X_train, y_train = balance_dataset(X_train, y_train, type=\"SMOTE\")\n",
    "\n",
    "\n",
    "# perform feature selection\n",
    "ftsl = FeatureSelector(model, **kwargs)\n",
    "ftsl = ftsl.fit(X_train, y_train)\n",
    "results = ftsl.get_results(cols)\n",
    "features_svc = list(map(lambda x: x.replace(\"'\", \"\"), list(results.iloc[0].features)))\n",
    "features_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best features to retrain / test model\n",
    "# new X and y split into train and test in cross validation\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "X_sfs = X_train.iloc[:, ftsl.get_feature_idx()]\n",
    "y_sfs = y_train\n",
    "\n",
    "\n",
    "X_val_sfs = X_val.iloc[:, ftsl.get_feature_idx()]\n",
    "\n",
    "\n",
    "\n",
    "# # train model on test data\n",
    "mean_f1 = get_cross_val_score(model, X_sfs, y_sfs, display_cm=True)\n",
    "print(\"Mean F1 Score: \", mean_f1,)\n",
    "print(\"Train-Val Split 80/20\")\n",
    "print(\"CV, done on train and val: Kfold = 2, test = 20%\")\n",
    "print(\"Features: \", features_svc)\n",
    "\n",
    "# y_pred = model.predict(X_val)\n",
    "# seaborn_conf_matrix(confusion_matrix(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_selection import FeatureSelector\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=SEED)\n",
    "kwargs = {\"selection_type\":\"forward\", \"floating\":True, \"scoring\":\"f1\", \"k_features\": len(X.columns), \"cv\": get_cross_validation(X_train, y_train)}\n",
    "cols = X.columns\n",
    "\n",
    "# scale training data\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "# balance data after scaling\n",
    "X_train, y_train = balance_dataset(X_train, y_train, type=\"SMOTE\")\n",
    "\n",
    "\n",
    "# perform feature selection\n",
    "ftsl = FeatureSelector(model, **kwargs)\n",
    "ftsl = ftsl.fit(X_train, y_train)\n",
    "results = ftsl.get_results(cols)\n",
    "features_dt = list(map(lambda x: x.replace(\"'\", \"\"), list(results.iloc[0].features)))\n",
    "features_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best features to retrain / test model\n",
    "# new X and y split into train and test in cross validation\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "X_sfs = X_train.iloc[:, ftsl.get_feature_idx()]\n",
    "y_sfs = y_train\n",
    "\n",
    "\n",
    "X_val_sfs = X_val.iloc[:, ftsl.get_feature_idx()]\n",
    "\n",
    "\n",
    "\n",
    "# # train model on test data\n",
    "mean_f1 = get_cross_val_score(model, X_sfs, y_sfs, display_cm=True)\n",
    "print(\"Mean F1 Score: \", mean_f1,)\n",
    "print(\"Train-Val Split 80/20\")\n",
    "print(\"CV, done on train and val: Kfold = 2, test = 20%\")\n",
    "print(\"Features: \", features_dt)\n",
    "\n",
    "# y_pred = model.predict(X_val)\n",
    "# seaborn_conf_matrix(confusion_matrix(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_selection import FeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "model = RandomForestClassifier(random_state=SEED)\n",
    "# model = SVC(random_state=SEED, kernel=\"linear\")\n",
    "kwargs = {\"selection_type\":\"forward\", \"floating\":True, \"scoring\":\"f1\", \"k_features\": len(X.columns), \"cv\": get_cross_validation(X_train, y_train)}\n",
    "cols = X.columns\n",
    "\n",
    "# scale training data\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "# balance data after scaling\n",
    "X_train, y_train = balance_dataset(X_train, y_train, type=\"SMOTE\")\n",
    "\n",
    "\n",
    "# perform feature selection\n",
    "ftsl = FeatureSelector(model, **kwargs)\n",
    "ftsl = ftsl.fit(X_train, y_train)\n",
    "results = ftsl.get_results(cols)\n",
    "features_rf = list(map(lambda x: x.replace(\"'\", \"\"), list(results.iloc[0].features)))\n",
    "features_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best features to retrain / test model\n",
    "# new X and y split into train and test in cross validation\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "X_sfs = X_train.iloc[:, ftsl.get_feature_idx()]\n",
    "y_sfs = y_train\n",
    "\n",
    "\n",
    "X_val_sfs = X_val.iloc[:, ftsl.get_feature_idx()]\n",
    "\n",
    "\n",
    "\n",
    "# # train model on test data\n",
    "mean_f1 = get_cross_val_score(model, X_sfs, y_sfs, display_cm=True)\n",
    "print(\"Mean F1 Score: \", mean_f1,)\n",
    "print(\"Train-Val Split 80/20\")\n",
    "print(\"CV, done on train and val: Kfold = 2, test = 20%\")\n",
    "print(\"Features: \", features_rf)\n",
    "\n",
    "# y_pred = model.predict(X_val)\n",
    "# seaborn_conf_matrix(confusion_matrix(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_selection import FeatureSelector\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "model = MLPClassifier(random_state=SEED, max_iter=1000)\n",
    "kwargs = {\"selection_type\":\"forward\", \"floating\":True, \"scoring\":\"f1\", \"k_features\": len(X.columns), \"cv\": get_cross_validation(X_train, y_train)}\n",
    "cols = X.columns\n",
    "\n",
    "# scale training data\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "# balance data after scaling\n",
    "X_train, y_train = balance_dataset(X_train, y_train, type=\"SMOTE\")\n",
    "\n",
    "\n",
    "# perform feature selection\n",
    "ftsl = FeatureSelector(model, **kwargs)\n",
    "ftsl = ftsl.fit(X_train, y_train)\n",
    "results = ftsl.get_results(cols)\n",
    "features_mlp = list(map(lambda x: x.replace(\"'\", \"\"), list(results.iloc[0].features)))\n",
    "features_mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best features to retrain / test model\n",
    "# new X and y split into train and test in cross validation\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "X_sfs = X_train.iloc[:, ftsl.get_feature_idx()]\n",
    "y_sfs = y_train\n",
    "\n",
    "\n",
    "X_val_sfs = X_val.iloc[:, ftsl.get_feature_idx()]\n",
    "\n",
    "\n",
    "\n",
    "# # train model on test data\n",
    "mean_f1 = get_cross_val_score(model, X_sfs, y_sfs, display_cm=True)\n",
    "print(\"Mean F1 Score: \", mean_f1,)\n",
    "print(\"Train-Val Split 80/20\")\n",
    "print(\"CV, done on train and val: Kfold = 2, test = 20%\")\n",
    "print(\"Features: \", features_mlp)\n",
    "\n",
    "# y_pred = model.predict(X_val)\n",
    "# seaborn_conf_matrix(confusion_matrix(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_selection import FeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "model = LogisticRegression(random_state=SEED)\n",
    "kwargs = {\"selection_type\":\"forward\", \"floating\":True, \"scoring\":\"f1\", \"k_features\": len(X.columns), \"cv\": get_cross_validation(X_train, y_train)}\n",
    "cols = X.columns\n",
    "\n",
    "# scale training data\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "# balance data after scaling\n",
    "X_train, y_train = balance_dataset(X_train, y_train, type=\"SMOTE\")\n",
    "\n",
    "\n",
    "# perform feature selection\n",
    "ftsl = FeatureSelector(model, **kwargs)\n",
    "ftsl = ftsl.fit(X_train, y_train)\n",
    "results = ftsl.get_results(cols)\n",
    "features_lr = list(map(lambda x: x.replace(\"'\", \"\"), list(results.iloc[0].features)))\n",
    "features_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best features to retrain / test model\n",
    "# new X and y split into train and test in cross validation\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "X_sfs = X_train.iloc[:, ftsl.get_feature_idx()]\n",
    "y_sfs = y_train\n",
    "\n",
    "\n",
    "X_val_sfs = X_val.iloc[:, ftsl.get_feature_idx()]\n",
    "\n",
    "\n",
    "\n",
    "# # train model on test data\n",
    "mean_f1 = get_cross_val_score(model, X_sfs, y_sfs, display_cm=True)\n",
    "print(\"Mean F1 Score: \", mean_f1,)\n",
    "print(\"Train-Val Split 80/20\")\n",
    "print(\"CV, done on train and val: Kfold = 2, test = 20%\")\n",
    "print(\"Features: \", features_lr)\n",
    "\n",
    "# y_pred = model.predict(X_val)\n",
    "# seaborn_conf_matrix(confusion_matrix(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_selection import FeatureSelector\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "model = XGBClassifier(random_state=SEED)\n",
    "kwargs = {\"selection_type\":\"forward\", \"floating\":True, \"scoring\":\"f1\", \"k_features\": len(X.columns), \"cv\": get_cross_validation(X_train, y_train)}\n",
    "cols = X.columns\n",
    "\n",
    "# scale training data\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "# balance data after scaling\n",
    "X_train, y_train = balance_dataset(X_train, y_train, type=\"SMOTE\")\n",
    "\n",
    "\n",
    "# perform feature selection\n",
    "ftsl = FeatureSelector(model, **kwargs)\n",
    "ftsl = ftsl.fit(X_train, y_train)\n",
    "results = ftsl.get_results(cols)\n",
    "features_xgb = list(map(lambda x: x.replace(\"'\", \"\"), list(results.iloc[0].features)))\n",
    "features_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best features to retrain / test model\n",
    "# new X and y split into train and test in cross validation\n",
    "X, y = create_dataset(clean_raw_data(\"Brdi_db_march.xlsx\"), target_col=\"NHL\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=SEED, stratify=y)\n",
    "\n",
    "X_sfs = X_train.iloc[:, ftsl.get_feature_idx()]\n",
    "y_sfs = y_train\n",
    "\n",
    "\n",
    "X_val_sfs = X_val.iloc[:, ftsl.get_feature_idx()]\n",
    "\n",
    "\n",
    "\n",
    "# # train model on test data\n",
    "mean_f1 = get_cross_val_score(model, X_sfs, y_sfs, display_cm=True)\n",
    "print(\"Mean F1 Score: \", mean_f1,)\n",
    "print(\"Train-Val Split 80/20\")\n",
    "print(\"CV, done on train and val: Kfold = 2, test = 20%\")\n",
    "print(\"Features: \", features_xgb)\n",
    "\n",
    "# y_pred = model.predict(X_val)\n",
    "# seaborn_conf_matrix(confusion_matrix(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "model1 = SVC(random_state=SEED)\n",
    "model2 = SVC(random_state=SEED)\n",
    "\n",
    "sfs1 = SFS(estimator=model, k_features=10, forward=True, floating=True, scoring='f1', cv=2)\n",
    "pipe = Pipeline([('sfs', sfs1), ('svc', model2)])\n",
    "\n",
    "param_grid =  {\n",
    "    'sfs__k_features': [1, 2, 3],\n",
    "    'sfs__estimator__kernel': ['linear', 'rbf'],\n",
    "    'sfs__estimator__C': [0.1, 1, 10, 100, 1000],\n",
    "\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='f1', \n",
    "                  n_jobs=-1, \n",
    "                  cv=2,\n",
    "                  refit=False)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters via GridSearch\", gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sfs(ftsl.selector.get_metric_dict(), kind='ci')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "* Grid Search \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets get baselines before tuning with models using features from feature selection and balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized cross validation for each search\n",
    "kf = get_cross_validation(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top features for SVC\n",
    "top_n_features =['weight', 'bimanual score: washer', 'Bimanual Score: Button', 'RT_HR', 'CMT: HR', 'cvRT_HR', 'Ball Path_V', 'Delta_Fullpath', 'Corrective_V', 'AE_HR', 'Delta_AE', 'Delta: VE', 'AbsOnAxis_HR', 'Delta_OnAxis', 'Delta_OffAxis']\n",
    "X_top_n_features = X[top_n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote, y_smote = balance_dataset(X, y, type=\"SMOTE\")\n",
    "X_adasyn, y_adasyn = balance_dataset(X, y, type=\"ADASYN\")\n",
    "X_random, y_random = balance_dataset(X, y, type=\"RANDOM\")\n",
    "X_knnor, y_knnor = balance_dataset(X, y, type=\"KNNOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unbalanced, all features\n",
    "f1_all_features = get_cross_val_score(SVC(random_state=SEED), get_cross_validation(X, y), X, y)\n",
    "\n",
    "# top n features\n",
    "f1_top_n_features = get_cross_val_score(SVC(random_state=SEED), get_cross_validation(X_top_n_features, y), X_top_n_features, y)\n",
    "\n",
    "# smote, all features\n",
    "f1_smote = get_cross_val_score(SVC(random_state=SEED), get_cross_validation(X_smote, y_smote), X_smote, y_smote)\n",
    "\n",
    "# adasyn, all features\n",
    "f1_adasyn = get_cross_val_score(SVC(random_state=SEED), get_cross_validation(X_adasyn, y_adasyn), X_adasyn, y_adasyn)\n",
    "\n",
    "# random, all features\n",
    "f1_random = get_cross_val_score(SVC(random_state=SEED), get_cross_validation(X_random, y_random), X_random, y_random)\n",
    "\n",
    "# knnor, all features\n",
    "f1_knnor = get_cross_val_score(SVC(random_state=SEED), get_cross_validation(X_knnor, y_knnor), X_knnor, y_knnor)\n",
    "\n",
    "print(f\"f1 all features, unbalanced: {f1_all_features}\")\n",
    "print(f\"f1 top n features: {f1_top_n_features}\")\n",
    "print(f\"f1 smote: {f1_smote}\")\n",
    "print(f\"f1 adasyn: {f1_adasyn}\")\n",
    "print(f\"f1 random: {f1_random}\")\n",
    "print(f\"f1 knnor: {f1_knnor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SVC(random_state=SEED)\n",
    "hyperparams = {\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"C\": [0.1, 1, 10, 100, 1000],\n",
    "    \"degree\": [1, 2, 3, 4, 5, 6],\n",
    "    \"gamma\" : [\"scale\", \"auto\"],\n",
    "    \"class_weight\": [\"balanced\", None],\n",
    "    \"break_ties\": [True, False],\n",
    "}\n",
    "\n",
    "features = ['age as of June 1', \"bimanual score: washer\", \"Delta_PV\", \"MT_HR\"]\n",
    "model_tuner = Tuner(model, hyperparams, cv=get_cross_validation(X[features], y))\n",
    "model_tuner.tune(X, y)\n",
    "\n",
    "best_params = model_tuner.get_best_params()\n",
    "best_estimator = model_tuner.get_best_estimator()\n",
    "results = model_tuner.get_results()\n",
    "\n",
    "print(\"best after model tuning\")\n",
    "print(model_tuner.get_best_estimator(), model_tuner.get_best_score(), model_tuner.get_best_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_set = ['age as of June 1', 'height', 'weight', 'previous concussions?', '# of concussions', 'bimanual score: washer', 'Bimanual Score: Button', 'RT_V', 'Delta_MT', 'CMT: V', 'CMT: HR', 'cvRT_V', 'cvRT_HR', 'stdRT_V', 'stdRT_HR', 'Corrective_V', 'Corrective_HR', 'PeakV_HR', 'AE_HR', 'Delta_AE', 'Delta: VE', 'AbsOnAxis_V', 'Delta_OnAxis', 'AbsOffAxis_V']\n",
    "feature_set = ['age as of June 1', \"bimanual score: washer\", \"Delta_PV\", \"MT_HR\"]\n",
    "X2 = X[feature_set]\n",
    "\n",
    "f1_all_features = get_cross_val_score(SVC(kernel=\"poly\", random_state=SEED, gamma=\"scale\", C=100, class_weight=\"balanced\", break_ties=False), get_cross_validation(X2, y), X2, y)\n",
    "f1_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "f1s = []\n",
    "for fs in results[\"features\"]:\n",
    "    fs = list(map(lambda x: x.replace(\"'\", \"\"), list(fs)))\n",
    "    X2 = X[fs]\n",
    "    f_score = get_cross_val_score( RandomForestClassifier(class_weight='balanced', max_depth=11, max_features=None,\n",
    "                       min_samples_leaf=4, min_samples_split=5,\n",
    "                       n_estimators=10), get_cross_validation(X2, y), X2, y)\n",
    "    f1s.append(f_score)\n",
    "    print(fs)\n",
    "    \n",
    "\n",
    "f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c53bd1381eb6c84fcfea4e1c0eea6b9539f3ac457d183ca9abd93d766138cca8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
